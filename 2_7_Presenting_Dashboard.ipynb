{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9732c625-09f1-4f85-aa99-5b28c78655fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda46886-16c8-4ceb-b35e-46dda9825147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial frac=0.20 -> 0.00 MB\n",
      " Saved bike_sample.csv (~0.00 MB)\n",
      "Saved top_stations.csv\n",
      " Saved daily_trips.csv (with temperature)\n"
     ]
    }
   ],
   "source": [
    "# -------- CONFIG: paths you likely already have --------\n",
    "FULL_TRIPS = \"citibike_2022_1months.csv\" \n",
    "WEATHER    = \"laguardia_weather_2022_1months.csv\" \n",
    "SAMPLE     = \"bike_sample.csv\"\n",
    "TOP_ST     = \"top_stations.csv\"\n",
    "DAILY      = \"daily_trips.csv\"\n",
    "\n",
    "# -------- 1) Sample trips to keep under 25 MB (seed=32) --------\n",
    "usecols = [\n",
    "    \"ride_id\",\"started_at\",\"ended_at\",\n",
    "    \"start_station_name\",\"end_station_name\",\n",
    "    \"start_lat\",\"start_lng\",\"end_lat\",\"end_lng\",\n",
    "    \"member_casual\"\n",
    "]\n",
    "df = pd.read_csv(FULL_TRIPS, usecols=usecols, parse_dates=[\"started_at\",\"ended_at\"], low_memory=False)\n",
    "\n",
    "# start with 20% and shrink if needed\n",
    "frac = 0.20\n",
    "while True:\n",
    "    sample = df.sample(frac=frac, random_state=32)\n",
    "    sample.to_csv(SAMPLE, index=False)\n",
    "    mb = os.path.getsize(SAMPLE) / (1024**2)\n",
    "    print(f\"Trial frac={frac:.2f} -> {mb:.2f} MB\")\n",
    "    if mb <= 25 or frac <= 0.05:\n",
    "        break\n",
    "    frac *= 0.8  # shrink if still too large\n",
    "\n",
    "print(f\" Saved {SAMPLE} (~{mb:.2f} MB)\")\n",
    "\n",
    "# -------- 2) Top stations for bar chart --------\n",
    "top_stations = (\n",
    "    sample.groupby(\"start_station_name\", as_index=False)\n",
    "          .size()\n",
    "          .rename(columns={\"size\":\"trip_count\"})\n",
    "          .sort_values(\"trip_count\", ascending=False)\n",
    ")\n",
    "top_stations.to_csv(TOP_ST, index=False)\n",
    "print(f\"Saved {TOP_ST}\")\n",
    "\n",
    "# -------- 3) Merge daily trips with weather for dual-axis --------\n",
    "daily_trips = (\n",
    "    sample.assign(date=sample[\"started_at\"].dt.date)\n",
    "          .groupby(\"date\", as_index=False)[\"ride_id\"].count()\n",
    "          .rename(columns={\"ride_id\":\"trip_count\"})\n",
    ")\n",
    "daily_trips[\"date\"] = pd.to_datetime(daily_trips[\"date\"])\n",
    "\n",
    "# read LaGuardia (NOAA daily long) and pivot\n",
    "w = pd.read_csv(WEATHER)\n",
    "w.columns = [c.strip().lower() for c in w.columns]\n",
    "w[\"date\"] = pd.to_datetime(w[\"date\"].astype(str).str[:10], errors=\"coerce\")\n",
    "\n",
    "weather_daily = (w.pivot_table(index=\"date\", columns=\"datatype\", values=\"value\", aggfunc=\"mean\")\n",
    "                   .reset_index())\n",
    "# convert tenths to actual units\n",
    "for col in [\"TMAX\",\"TMIN\",\"PRCP\"]:\n",
    "    if col in weather_daily.columns:\n",
    "        weather_daily[col] = weather_daily[col] / 10.0\n",
    "\n",
    "if {\"TMAX\",\"TMIN\"} <= set(weather_daily.columns):\n",
    "    weather_daily[\"TAVG_C\"] = (weather_daily[\"TMAX\"] + weather_daily[\"TMIN\"])/2\n",
    "elif \"TMAX\" in weather_daily.columns:\n",
    "    weather_daily[\"TAVG_C\"] = weather_daily[\"TMAX\"]\n",
    "else:\n",
    "    weather_daily[\"TAVG_C\"] = np.nan\n",
    "weather_daily[\"TAVG_F\"] = weather_daily[\"TAVG_C\"] * 9/5 + 32\n",
    "\n",
    "daily = daily_trips.merge(weather_daily, on=\"date\", how=\"left\")\n",
    "daily.to_csv(DAILY, index=False)\n",
    "print(f\" Saved {DAILY} (with temperature)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb5a688-e212-4dec-bb52-c739eabb5eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 00:48:59.669 No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-22 00:48:59.673 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "\n",
    "# --------------------\n",
    "# Page config\n",
    "# --------------------\n",
    "st.set_page_config(page_title=\"NYC Citi Bike Dashboard – Part 2\", layout=\"wide\")\n",
    "\n",
    "# --------------------\n",
    "# Sidebar navigation\n",
    "# --------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "page = st.sidebar.selectbox(\n",
    "    \"Go to page:\",\n",
    "    [\n",
    "        \"Intro\",\n",
    "        \"Trips vs Temperature\",\n",
    "        \"Top Stations\",\n",
    "        \"Kepler Map\",\n",
    "        \"Extra: Hour x Weekday\",\n",
    "        \"Recommendations\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Data loader (cached)\n",
    "# --------------------\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    trips_path = \"bike_sample.csv\"\n",
    "    tops_path  = \"top_stations.csv\"\n",
    "    daily_path = \"daily_trips.csv\"\n",
    "\n",
    "    if not all(os.path.exists(p) for p in [trips_path, tops_path, daily_path]):\n",
    "        st.error(\"Missing one of: bike_sample.csv, top_stations.csv, daily_trips.csv. Run the notebook step first.\")\n",
    "        st.stop()\n",
    "\n",
    "    trips = pd.read_csv(trips_path, parse_dates=[\"started_at\",\"ended_at\"])\n",
    "    top_stations = pd.read_csv(tops_path)\n",
    "    daily = pd.read_csv(daily_path, parse_dates=[\"date\"])\n",
    "    return trips, top_stations, daily\n",
    "\n",
    "trips, top_stations, daily = load_data()\n",
    "\n",
    "# --------------------\n",
    "# Optional global filters\n",
    "# --------------------\n",
    "with st.sidebar.expander(\"Filters\", expanded=False):\n",
    "    # date range for daily chart\n",
    "    dmin, dmax = daily[\"date\"].min().date(), daily[\"date\"].max().date()\n",
    "    dsel = st.date_input(\"Date range (daily)\", (dmin, dmax), min_value=dmin, max_value=dmax)\n",
    "\n",
    "    # user type filter for extra chart\n",
    "    user_types = sorted(trips[\"member_casual\"].dropna().unique().tolist())\n",
    "    selected_types = st.multiselect(\"User type\", user_types, default=user_types)\n",
    "\n",
    "daily_f = daily[(daily[\"date\"] >= pd.to_datetime(dsel[0])) & (daily[\"date\"] <= pd.to_datetime(dsel[1]))]\n",
    "\n",
    "# --------------------\n",
    "# PAGES\n",
    "# --------------------\n",
    "if page == \"Intro\":\n",
    "    st.title(\"NYC Citi Bike – Interactive Dashboard (Part 2)\")\n",
    "    st.markdown(\"\"\"\n",
    "**Purpose.** Explore station popularity, seasonality vs temperature, and origin–destination flows to support **supply & rebalancing decisions**.\n",
    "\n",
    "**What’s inside:**\n",
    "- **Trips vs Temperature** *(dual-axis)* — demand seasonality vs weather.\n",
    "- **Top Stations** *(bar)* — busiest origins.\n",
    "- **Kepler Map** — station‑to‑station flows (arcs).\n",
    "- **Extra** — hourly/weekday usage heatmap.\n",
    "- **Recommendations** — actions to improve bike/dock availability.\n",
    "\n",
    "_Data note: using a random sample (seed=32) under 25 MB for easy sharing & deployment._\n",
    "\"\"\")\n",
    "\n",
    "elif page == \"Trips vs Temperature\":\n",
    "    st.header(\"Daily Trips vs Temperature (LaGuardia)\")\n",
    "    # choose available temp column\n",
    "    temp_col = None\n",
    "    for c in [\"TAVG_F\", \"TAVG_C\", \"TMAX\"]:\n",
    "        if c in daily_f.columns:\n",
    "            temp_col = c\n",
    "            break\n",
    "\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    # temperature on left\n",
    "    fig.add_trace(go.Scatter(x=daily_f[\"date\"], y=daily_f[temp_col],\n",
    "                             name=f\"Temperature ({temp_col})\", mode=\"lines\"),\n",
    "                  secondary_y=False)\n",
    "    # trips on right\n",
    "    fig.add_trace(go.Scatter(x=daily_f[\"date\"], y=daily_f[\"trip_count\"],\n",
    "                             name=\"Trips\", mode=\"lines\"),\n",
    "                  secondary_y=True)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Daily Trips vs Temperature\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0)\n",
    "    )\n",
    "    fig.update_yaxes(title_text=f\"Temperature ({temp_col})\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Trips\", secondary_y=True)\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "**Interpretation.** Trips increase with warmer temps and dip in colder periods.  \n",
    "Watch shoulder seasons and spikes on unseasonably warm days to tune **rebalancing and staffing**.\n",
    "\"\"\")\n",
    "\n",
    "elif page == \"Top Stations\":\n",
    "    st.header(\"Top 20 Start Stations\")\n",
    "    fig = px.bar(\n",
    "        top_stations.head(20),\n",
    "        x=\"start_station_name\",\n",
    "        y=\"trip_count\",\n",
    "        color=\"trip_count\",\n",
    "        color_continuous_scale=\"Blues\",\n",
    "        title=\"Most Popular Start Stations\"\n",
    "    )\n",
    "    fig.update_layout(xaxis_tickangle=45, xaxis_title=\"\", yaxis_title=\"Trips\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "**Interpretation.** These stations consistently show **high demand**.  \n",
    "Consider **higher dock counts**, **AM placement** and **PM collection**, and **incentives** to rebalance user flows.\n",
    "\"\"\")\n",
    "\n",
    "elif page == \"Kepler Map\":\n",
    "    st.header(\"Station Flows (Kepler.gl)\")\n",
    "    html_file = \"nyc_trip_map.html\"\n",
    "    if os.path.exists(html_file):\n",
    "        st.components.v1.html(open(html_file, \"r\", encoding=\"utf-8\").read(), height=620)\n",
    "        st.caption(\"Tip: Use the filter panel inside the map to focus on high trip_count corridors.\")\n",
    "    else:\n",
    "        st.warning(f\"Add {html_file} to this folder to display the Kepler map.\")\n",
    "    st.markdown(\"\"\"\n",
    "**Interpretation.** Thick arcs mark **major corridors** (Midtown and bridge approaches).  \n",
    "These are candidates for **capacity boosts** and **tighter truck loops**.\n",
    "\"\"\")\n",
    "\n",
    "elif page == \"Extra: Hour x Weekday\":\n",
    "    st.header(\"Usage by Hour & Weekday (Filtered by user type)\")\n",
    "    df = trips[trips[\"member_casual\"].isin(selected_types)].copy()\n",
    "    df[\"hour\"] = df[\"started_at\"].dt.hour\n",
    "    df[\"weekday\"] = df[\"started_at\"].dt.day_name()\n",
    "    # order weekdays\n",
    "    order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "    df[\"weekday\"] = pd.Categorical(df[\"weekday\"], categories=order, ordered=True)\n",
    "\n",
    "    heat = (df.groupby([\"weekday\",\"hour\"], as_index=False)[\"ride_id\"].count()\n",
    "              .rename(columns={\"ride_id\":\"trips\"}))\n",
    "\n",
    "    fig = px.density_heatmap(heat, x=\"hour\", y=\"weekday\", z=\"trips\",\n",
    "                             color_continuous_scale=\"Viridis\",\n",
    "                             title=\"Trips by Hour & Weekday\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "    st.markdown(\"\"\"\n",
    "**Insight.** **AM/PM commute peaks** on weekdays; broader midday peaks on weekends.  \n",
    "Schedule rebalancing and staffing to match these patterns.\n",
    "\"\"\")\n",
    "\n",
    "elif page == \"Recommendations\":\n",
    "    st.header(\"Recommendations\")\n",
    "    st.markdown(\"\"\"\n",
    "- **Seasonal scaling:** Reduce active fleet **~20–30% Nov–Apr**, keep service robust at commute hubs.\n",
    "- **Waterfront capacity:** Add/expand docks near parks & promenades; pilot **pop‑up docks** on summer weekends.\n",
    "- **Rebalancing:** Guarantee **dock availability** at top stations via **AM placement** and **PM returns**; plan **hourly truck loops** for peaks.\n",
    "- **Predictive ops:** Adjust for **weather** (heat/cold/rain) using recent demand + forecast signals.\n",
    "- **Incentives:** Offer **credits** for ending trips at underutilized nearby docks to self‑rebalance.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1667e747-6c13-40b9-abfb-9c3a29ee2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 2_7_Presenting_Dashboard.ipynb to script\n",
      "[NbConvertApp] Writing 9684 bytes to app2.py\n"
     ]
    }
   ],
   "source": [
    "# run this in the folder that contains your notebook\n",
    "!jupyter nbconvert --to script \"2_7_Presenting_Dashboard.ipynb\" --output app2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15456d-d64e-432e-9f2e-6f84a1219b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
